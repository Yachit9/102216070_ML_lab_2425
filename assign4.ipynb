{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0   1.952367   1.727134   1.633400   1.704187   1.802326   1.609009   \n",
      "1   0.265381   0.376219   0.565970   0.288568   0.396733   0.441889   \n",
      "2   0.851689   1.088704   0.966922   1.055404   1.088373   0.884301   \n",
      "3   2.337833   2.306420   2.172875   2.276522   2.217472   2.264704   \n",
      "4   1.750246   1.931571   1.934196   1.690704   1.832813   1.726962   \n",
      "\n",
      "   feature_7    target  \n",
      "0   1.619558  2.448355  \n",
      "1   0.279103  0.820787  \n",
      "2   0.899871 -0.135743  \n",
      "3   2.350357  0.812428  \n",
      "4   1.891040  1.797122  \n"
     ]
    }
   ],
   "source": [
    "#dataset generation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 100\n",
    "\n",
    "# Generate a base feature\n",
    "base_feature = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# Generate highly correlated features by adding slight noise to the base feature\n",
    "X = np.zeros((n_samples, 7))\n",
    "for i in range(7):\n",
    "    X[:, i] = base_feature + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "# Convert to DataFrame for easier handling and naming\n",
    "feature_names = [f\"feature_{i+1}\" for i in range(7)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Generate a target variable with some dependence on the features\n",
    "true_coefficients = np.array([3, -2, 1.5, -4, 2.5, -1, 0.5])  # Coefficients for the features\n",
    "y = X.dot(true_coefficients) + np.random.normal(0, 0.5, n_samples)  # Add some noise to the target\n",
    "\n",
    "# Add target variable to the DataFrame\n",
    "df['target'] = y\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for ridge regression\n",
    "def ridge_regression(X,y,alpha=0.01,learning_rate=1e-15,epochs=1000):\n",
    "    n,k=X.shape\n",
    "    theta=np.zeros(k)\n",
    "\n",
    "    cost_history=[]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_pred=X.dot(theta)\n",
    "        error=y_pred-y\n",
    "        mse=(1/(2*n)*(np.sum(error**2)))\n",
    "\n",
    "        regularization=(alpha/(2*n))*np.sum(theta[1:]**2)\n",
    "\n",
    "        cost=mse+regularization\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        gradient=(1/n)*X.T.dot(error) +(alpha/n)*np.r_[0,theta[1:]]\n",
    "\n",
    "        theta=theta-learning_rate*gradient\n",
    "\n",
    "        if epoch %100==0:\n",
    "          print(f\"Epoch {epoch}, Cost: {cost}\")\n",
    "\n",
    "        return theta,cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Epoch 0, Cost: 0.5073832781442862\n",
      "Best Parameters:\n",
      "Learning Rate: 0.1\n",
      "Regularization Parameter (alpha): 1e-15\n",
      "Minimum Cost: [0.5073832781442862]\n",
      "Maximum R^2 Score: 0.2911298830854194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "X = np.hstack([np.ones((n_samples, 1)), df[feature_names].values])#here we are adding 1's to the column so that we can get 1 for the intercept term\n",
    "y = df['target'].values\n",
    "\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "regularization_params = [1e-15, 1e-10, 1e-5, 1e-3, 0, 1, 10, 20]\n",
    "\n",
    "best_r2 = -np.inf  # Initialize with lowest possible R2\n",
    "best_params = {'learning_rate': None, 'alpha': None, 'theta': None, 'cost': None}\n",
    "\n",
    "# Grid Search\n",
    "for lr in learning_rates:\n",
    "    for alpha in regularization_params:\n",
    "        theta, final_cost = ridge_regression(X, y, alpha, lr)\n",
    "        \n",
    "        # Predictions and R2 Score calculation\n",
    "        y_pred = X.dot(theta)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        \n",
    "        # Track best parameters\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_params['learning_rate'] = lr\n",
    "            best_params['alpha'] = alpha\n",
    "            best_params['theta'] = theta\n",
    "            best_params['cost'] = final_cost\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(\"Learning Rate:\", best_params['learning_rate'])\n",
    "print(\"Regularization Parameter (alpha):\", best_params['alpha'])\n",
    "print(\"Minimum Cost:\", best_params['cost'])\n",
    "print(\"Maximum R^2 Score:\", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Hitters (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "0    293    66      1    30   29     14      1     293     66       1     30   \n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "\n",
       "   CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary NewLeague  \n",
       "0    29      14      A        E      446       33      20     NaN         A  \n",
       "1   414     375      N        W      632       43      10   475.0         N  \n",
       "2   266     263      A        W      880       82      14   480.0         A  \n",
       "3   838     354      N        E      200       11       3   500.0         N  \n",
       "4    46      33      N        E      805       40       4    91.5         N  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat         0\n",
       "Hits          0\n",
       "HmRun         0\n",
       "Runs          0\n",
       "RBI           0\n",
       "Walks         0\n",
       "Years         0\n",
       "CAtBat        0\n",
       "CHits         0\n",
       "CHmRun        0\n",
       "CRuns         0\n",
       "CRBI          0\n",
       "CWalks        0\n",
       "League        0\n",
       "Division      0\n",
       "PutOuts       0\n",
       "Assists       0\n",
       "Errors        0\n",
       "Salary       59\n",
       "NewLeague     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical using one-hot encoding\n",
    "data = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate input and output features\n",
    "X = data.drop('Salary', axis=1)\n",
    "y = data['Salary']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+04, tolerance: 4.367e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.5748)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.5748)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.5748)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# Initialize the models with specified parameters\n",
    "linear_model = LinearRegression()\n",
    "ridge_model = Ridge(alpha=0.5748)\n",
    "lasso_model = Lasso(alpha=0.5748)\n",
    "\n",
    "# Train each model\n",
    "linear_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: R^2 = 0.2907451855798151 , MSE = 211.11596204561255\n",
      "Ridge Regression: R^2 = 0.30003596988293757 , MSE = 204.66417420122414\n",
      "Lasso Regression: R^2 = 0.29928590166965496 , MSE = 206.20588725930833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Make predictions\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate each model\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "mse_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "mse_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Linear Regression: R^2 =\", r2_linear, \", MSE =\", mse_linear)\n",
    "print(\"Ridge Regression: R^2 =\", r2_ridge, \", MSE =\", mse_ridge)\n",
    "print(\"Lasso Regression: R^2 =\", r2_lasso, \", MSE =\", mse_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "df=pd.read_csv('Boston_Housing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['MEDV']\n",
    "X=df.drop('MEDV',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2523.376596859873, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1555.8220121814525, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2686.672700541081, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1494.461345870489, tolerance: 2.7297569226006195\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1917.811691468139, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.475e+02, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(alphas=[1e-15, 1e-10, 1e-05, 0.001, 0.1, 1, 10, 20], cv=5,\n",
       "        max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(alphas=[1e-15, 1e-10, 1e-05, 0.001, 0.1, 1, 10, 20], cv=5,\n",
       "        max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(alphas=[1e-15, 1e-10, 1e-05, 0.001, 0.1, 1, 10, 20], cv=5,\n",
       "        max_iter=10000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# Define a range of alphas for cross-validation\n",
    "alphas = [1e-15, 1e-10, 1e-5, 1e-3, 0.1, 1, 10, 20]\n",
    "\n",
    "# Ridge regression with cross-validation\n",
    "ridge_cv = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Lasso regression with cross-validation\n",
    "lasso_cv = LassoCV(alphas=alphas, max_iter=10000, cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression:\n",
      "Best alpha: 10.0\n",
      "R^2 score: 0.6659677905050475\n",
      "MSE: 24.495845619666415\n",
      "\n",
      "Lasso Regression:\n",
      "Best alpha: 1e-15\n",
      "R^2 score: 0.6687594935356338\n",
      "MSE: 24.29111947497339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Ridge model predictions and evaluation\n",
    "ridge_predictions = ridge_cv.predict(X_test)\n",
    "ridge_r2 = r2_score(y_test, ridge_predictions)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_predictions)\n",
    "\n",
    "# Lasso model predictions and evaluation\n",
    "lasso_predictions = lasso_cv.predict(X_test)\n",
    "lasso_r2 = r2_score(y_test, lasso_predictions)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Ridge Regression:\")\n",
    "print(\"Best alpha:\", ridge_cv.alpha_)\n",
    "print(\"R^2 score:\", ridge_r2)\n",
    "print(\"MSE:\", ridge_mse)\n",
    "\n",
    "print(\"\\nLasso Regression:\")\n",
    "print(\"Best alpha:\", lasso_cv.alpha_)\n",
    "print(\"R^2 score:\", lasso_r2)\n",
    "print(\"MSE:\", lasso_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
